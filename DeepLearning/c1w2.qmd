---
title: "W2:Introduction to Computer Vision"
execute:
  warning: false
  error: false
format:
  html:
    toc: true
    toc-location: right
    code-fold: show
    code-tools: true
    number-sections: true
    code-block-bg: true
    code-block-border-left: "#31BAE9"
---

Week2 Introduction to Computer Vision

Welcome to week 2 of the course! In week 1 you learned all about how Machine Learning and Deep Learning is a new programming paradigm. This week youâ€™re going to take that to the next level by beginning to solve problems of computer vision with just a few lines of code!

Check out this conversation between Laurence and Andrew where they discuss it and introduce you to Computer Vision!

```{python}
import sys
print(sys.version)
```


```{python}
import tensorflow as tf
import numpy as np
from tensorflow import keras
import os
print(tf.__version__)
```



![](images/1.png)



# Load the data

```{python}

# Load the Fashion MNIST dataset
fmnist = tf.keras.datasets.fashion_mnist

```

```{python}
# Load the training and test split of the Fashion MNIST dataset
(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()
```

```{python}
import numpy as np
import matplotlib.pyplot as plt

# You can put between 0 to 59999 here
index = 0

# Set number of characters per row when printing
np.set_printoptions(linewidth=320)

# Print the label and image
print(f'LABEL: {training_labels[index]}')
print(f'\nIMAGE PIXEL ARRAY:\n {training_images[index]}')
```

```{python}
# Visualize the image
plt.imshow(training_images[index])
```

You'll notice that all of the values in the number are between 0 and 255. If you are training a neural network especially in image processing, for various reasons it will usually learn better if you scale all values to between 0 and 1. It's a process called normalization and fortunately in Python, it's easy to normalize an array without looping. You do it like this:

```{python}
# Normalize the pixel values of the train and test images
training_images  = training_images / 255.0
test_images = test_images / 255.0
```

# define model

**Sequential**: That defines a sequence of layers in the neural network.

**Flatten**: Remember earlier where our images were a 28x28 pixel matrix when you printed them out? Flatten just takes that square and turns it into a 1-dimensional array.

**Dense**: Adds a layer of neurons

Each layer of neurons need an activation function to tell them what to do. There are a lot of options, but just use these for now:

**ReLU** effectively means:

if x \> 0: return x

else: return 0

**Softmax** takes a list of values and scales these so the sum of all elements will be equal to 1

```{python}
model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), 
                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), 
                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])
```



```{python}
# Print the model summary
model.summary()
```

# compile model

```{python}
model.compile(optimizer = tf.optimizers.Adam(),
              loss = 'sparse_categorical_crossentropy',
              metrics=['accuracy'])
```

# Callbacks

```{python}
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    '''
    Halts the training when the loss falls below 0.4

    Args:
      epoch (integer) - index of epoch (required but unused in the function definition below)
      logs (dict) - metric results from the training epoch
    '''

    # Check the loss
    if(logs.get('loss') < 0.3):

      # Stop if threshold is met
      print("\nLoss is lower than 0.4 so cancelling training!")
      print("cancelling training with:")
      print(epoch+1)
      self.model.stop_training = True

# Instantiate class
callbacks = myCallback()
```

# train model

```{python}
model.fit(training_images, training_labels, epochs=10,callbacks=[callbacks])
```

# evaluate

```{python}
# Evaluate the model on unseen data
model.evaluate(test_images, test_labels)
```

# resource:

https://www.coursera.org/learn/introduction-tensorflow/home/info

https://github.com/https-deeplearning-ai/tensorflow-1-public/tree/main/C1

https://github.com/zalandoresearch/fashion-mnist
